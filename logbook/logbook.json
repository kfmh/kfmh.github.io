{
    "2023": {
        "december": {
            "2023-12-03":{
                    "weekday": "Sunday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Set out to implement speech-to-text (STT) functionality to move chess pieces and text-to-speech (TTS) to hear the move from the chess engine.",
                    "methods":"For generating TTS and STT I’m using Huggingface api-inference. TTS is done with the fastspeech2-en-ljspeech model by Meta, formerly facebook. STT I’m using OpenAI’s whisper-large-v2. To keep expenses low while focusing on interaction design and writing necessary ground architecture, I am using free api-inference endpoints with limited computational power. This leads to slow responses, but for now this is not an issue.",
                    "agenda":"",
                    "insights":"As the purpose of the uw-chess is to play blindfold Chess.TI haven't put much thought into chess-board rendering. For now the chess-board is rendered with ASCII graphics, this is not a conscious choice, but the default render the python-chess package generates when printing to the terminal window. While testing with ASCII design I noticed how the basic representation of the board is good for practicing with your eyes open. It’s just slightly easier than having your eyes closed. So I will add a flag for choosing ASCII, Classic-2D or only voice.",
                    "conclusions":"uw-chess is coming along nicely, the absolute basics are in place while minor detales still need to be addressed for the POC. Next up is to add conditions to the UCI (Universal Chess Interface) formatting function for the STT response when attempting to castle, or when a pawn reaches the 8th rank.",
                    "image": "./logbook/images/2023-12-03_gameplay.png",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-04":{
                    "weekday": "Monday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Cleaning up functions with error handling, adding flags for passing arguments like bot difficulty level and chess board graphics. ",
                    "methods":"The whisper-large-v2 STT model is slow and it is becoming frustrating. Switch to a community created distil-whisper model with supposedly faster inference. whisper-large-v2 was api-inference, and distil-whisper is running locally on my apple silicone M2. It should run faster but there is some process taking unnecessary time. Added a Pygame render for the chess board.",
                    "agenda":"",
                    "insights":"There is more work revealing itself all the time, but I need to keep it simple and do rapid prototyping.",
                    "conclusions":"Everything takes longer than I think, still making great progress, maybe even moving a little bit too fast. Having lots of fun though, chess is an amazing game and I really can't wait to start playing full games.",
                    "image": "./logbook/images/2023-12-04_gameplay.png",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-05":{
                    "weekday": "Tuesday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Today's objective was to finish the bare minimum to start user testing. This included some basic error handling, cleaning up the game render loop, adding argument parsing for bot difficulty and improving the UCI (Universal Chess Interface) formatting from the speech to text response. I'm the only user at this stage but at the end of the week I should have a functioning python package ready for testing.",
                    "methods":"For rendering the 2D chess board I'm using Pygame's python package, it gets the job done for rapid prototyping but the package is overkill for just rendering chess moves. Once I have the interaction design working I'll code a custom rendering process. I'm running distil-large-v2, (a distilled version of Open AI’s Whisper model) locally on my Mac M2 and it works really well, but it's a two step process. First there is a speech recognition process, recording the voice and I need to configure it better. A lot of time is wasted on recording audio long after I'm finished talking or it stops recording while I'm still pondering the next move and goes through all the steps after before looping around to recording again. I'll have to configure the ambient noise threshold and shorten the time of listening to silence. For the text to speech I’m using facebook/fastspeech2-en-ljspeech via a Hugging Face api-inference endpoint. This is also slow but I know it’s limited processing for the free API which I’m grateful for. My plan is to find a lightweight model I can run locally or spin up my own inference endpoint and pay for stronger compute power. It is also not so reliable on the TTS, but I believe it has to do with my UCI formatting function.",
                    "agenda":"",
                    "insights":"Recorded my first project demo tonight, wow it’s difficult to be good at sharing the enthusiasm, but I'm really tired and it's late. Marketing is something I’ve been reading and learning more about, it’s a good lesson to force myself to just get something on video even if I'm the only one excited about it.",
                    "conclusions":"I honestly had a blast today, I finally got to play and I can see myself getting really nerdy with blindfold chess. The goal for tomorrow is to get through a full game, for that i'll need to fix some more bugs.",
                    "image": "",
                    "video_url": "https://www.youtube.com/embed/1wvanX-nkVc?si=2qsHtPq2mhasSZAs",
                    "alt_text": ""
                },
            "2023-12-06":{
                    "weekday": "Wednesday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"The goal was to complete a full game without the program breaking and to improve the runtime functions, but most of the day was spent on fixing UX on this site, scheduling LinkedIn content and planning other projects.",
                    "methods":"The text-to-speech and speech-to-text is far from optimal. Managed to look at the code base but no improvements worth mentioning. In order to complete a python package by monday i'll probably need to rebuild some classes from scratch. The function I'm using now I've copied from another project I’m working on using STT and TTS. ",
                    "agenda":"",
                    "insights":"I enjoy designing, drawing and all that jazz, but I hate web design, maybe because I'm not schooled in it or because so much time is wasted on “pixel pushing”. But Im happy with this site now and won't have to work on it for a long time now. ",
                    "conclusions":"Every day can’t be 2 steps forward, today was at least not a step back. What feels good though is keeping this logbook. It is an improvement to my development journey, and I see the value in evaluating the day like this. ",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-07":{
                    "weekday": "Thursday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Yesterday It felt like I was moving sideways and today I was soaring. Took a look at both speech-to-text (STT) and text-to-speech (TTS) to see where I could optimize. Both scripts were initially created for another project using a similar interaction design so it's kind of like I picked a wrench from the toolbox and used it as a wrench as a hammer. ",
                    "methods":"I removed half the STT script because there was only one function I needed, it uses a speech recognition package that I previously only used as an event listener for activating a more robust STT model. Because playing chess only needs short repetitive phrases I wanted to see if the speech recognition process was enough for this purpose. It’s safe to say it was not, but it’s a step forward. I'll need to investigate if I can fine tune it or go back to the old version using a distilled Whisper model which I know I can fine tune. ",
                    "agenda":"",
                    "insights":"I had something good i thought about earlier today, but i can't remember now. Need to start making notes throughout the day.",
                    "conclusions":"It was a good day, I needed to look at the event loop and specifically the speech to text. Text to speech is fine now for the POC, but I need to work on the audio error messages. I should try doing a real blindfold test tomorrow to get an accurate feel. Probably a lot I'm missing with the blindfold interaction design.",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-08":{
                    "weekday": "Friday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Today I took a somewhat educational and creative break. Been reading about AGI and philosophizing about where I could take UW-chess. I still managed to record a new demo with the latest updates, and found some unnecessary  processes I could optimize. The game is slightly improved and I feel confident I'll finish the POC by monday.",
                    "methods":"Implemented a decorator function for logging the duration it takes to run functions in the event loop and noticed that rendering the game board was extremely inefficient. Also decreased the sleep() function from 2s to 0.5s. I implemented it to give some space between player actions and chess-bot action. These improvements were done after the demo video. I also drew some chess pieces but they ended up looking really bad when rendered to the board",
                    "agenda":"",
                    "insights":"At this stage the POC is almost ready, but it lacks a lot of interaction design. Tomorrow i'll do test blind folded and from that i'm sure i'll find valuable insights.",
                    "conclusions":"This isn’t a complicated application, neither the interaction design or the machine learning is advanced at this stage but this project has a lot of hidden possibilities that is exciting to think about. ",
                    "image": "./logbook/images/chess_pieces.png",
                    "video_url": "https://www.youtube.com/embed/9C3ttUqd-b4?si=dgzWE9UG5MhxepBp",
                    "alt_text": ""
                },
            "2023-12-09":{
                    "weekday": "Saturday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Testing blindfold interaction design to find where I should focus improvements before finalizing the proof of concept for monday. Besides playing a lot of games another way of practicing chess is to look at specific scenarios, but the first step of blindfold chess is to practice awareness so implementing a function for randomly generating a number of pieces to start with. For example starting with only 8 pieces in total on the board.  This would be an intermediary level to practice board awareness, and gradually increase how many pieces to keep track of.",
                    "methods":"The first thing that is disorienting is the speech-to-text record looping. There is a short gap when the loop circles back around where it isn't recording. To mitigate this poor interaction for now I have an alert sound for each cycle not returning a proper UCI string, but I'm working on making the STT recording and speech analysis asynchronous function that can run continuously so there isn’t a gap between each cycle. The function for generating a random chess scenario with a specific set of pieces is for now a loop that plays the game until the desired amount of pieces are left, then the function returns all the moves made and the current board for the user to take over. ",
                    "agenda":"",
                    "insights":"For the POC I will focus on the new function for random board generation, and the STT loop async architecture. I'm very new to working with asynchronous functions so this is a bit of a challenge but it will improve the overall experience.",
                    "conclusions":"I'm not sure i'll finish till monday, but one full day should be enough for this. It doesn't feel like much left but it probably is. ",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-10":{
                    "weekday": "Sunday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Today I set out to Finish a proof of concept (POC) that can be installed as a python package. The feature I'm most excited about is the random board setup generator. Since it is a training tool for practicing blindfold chess there should be a way of incrementally increasing the difficulty, so there will be 2 parameters for difficulty as part of the POC version. The 1st parameter is the amount of pieces on the board so users can start tracking 4 and gradually increase to - 32 pieces. The 2nd parameter is rendering chess-board coordinate visibility. Board will have 3 levels with easy = (x,y) visible for each tile, moderate = classic coordinates viability showing left column, and bottom rank. And a hard = blank board. - [13:30]",
                    "methods":"The generated random board function is a loop that plays the game until the required amount of pieces are left, appends all moves to a list and returns all moves and current chessboard state. - [15:30]. To make the bord coordinates rendering easy to code I premade a PNG background element, which also requires less work from the script. I don't know why I didn't do this from the start - [18:30]. The Python package is done, now what’s left is to write documentation and update. I'll leave that for tomorrow - [00:00]",
                    "agenda":"",
                    "insights":"Today I've tried writing logs frequently throughout the day. I make more sense and I don't forget as much. I’ll try keeping up with this logbook model. Besides feeling good that I've finished most of the work for the POC, I got inspired to display this project on the LinkedIn group “Python Developers Community”, it is in line with the guidelines of the content they post. - [00:00]",
                    "conclusions":"It was a good day to program. There is still a lot of small fixes to be made but i'll start working on a separate branch now and leave the main branch as is - [00:00]",
                    "image": "./logbook/images/chess_board_render.png",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-11":{
                    "weekday": "Monday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Today's main focus is to finalize the proof of concept and python package. The application is far from decent but it works enough to get a feel for its potential. Going over the code today I'll implement an “Occam's razor” approach, simplify and remove rather than write more lines - [09:00].",
                    "agenda":["Argpaser for chess engine path", "Update readme with installation and usage instructions", "Write basic documentation", "Improve code comments, docstrings and readability"],
                    "methods":"Using Chat GPT to generate docstring and comments, there is still a lot I have to add but it probably cuts the time in half. -[13.00]",
                    "insights":"Creating a well structured base architecture and comprehensive documentation from the start will make this project a lot more manageable for future improvements and ideas. It’s amazing how much faster I can work when I can generate boilerplate on the fly. Feel like I'm one of 5 people - [13.00]. The “Read Me” is updated with installation instructions and basic requirements. Haven't really done any logic updates, but will dedicate the rest of the week for that and proper documentation - [16.00].",
                    "conclusions":"Like I stated in today's objective “The application is far from decent” but boy does it feel good to push Undr Wolf V1 - [16.00].",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-12":{
                    "weekday": "Tuesday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Today is an educational day, going to dive into asynchronous programming, threading and multiprocessing. One of these approaches will improve the interaction with the speech-to-text STT event. Since one event is recording and the other is analyzing the recording, this should be possible to continuously record and analyze in tandem, so thus to not have a break not noticeable to the user, leading to disorientation - [09:00].",
                    "agenda":[],
                    "methods":"It seems like multiprocessing will work best, even though the workload now is simple, sperateing recording and analyzing on dedicated processes leaves upside to add on to the STT functionality - [21:00].",
                    "insights":"Natural communication with AI is very interesting, while it isn’t anything innovative in and of itself. Creating natural voice communion for the user is a very interesting challenge, most of all because I have to evaluate how the system should process the information. I.e 2 cognitive processes sharing information while continuously working, like the brain. We as humans don’t process synchronously, or asynchronously. It feels closer to multiprocessing - [21:00].",
                    "conclusions":"Did not get much done on the uw_chess, but did move the needle slightly. Testing multiprocessing is a milestone for me in my developer journey. I can see how powerful multiprocessing is when building AI applications - [21:00].",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-13":{
                    "weekday": "Wednesday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Create a working multiprocessing script for speech to text STT, so that no speech is missed. If I create a working function for this I can later switch out the model doing the analysis to a stronger to improve reliability and over all interaction design - [08:30].",
                    "agenda":["STT multiprocessing prototype", "Revise 'Read Me'", "Revise code documentation"],
                    "methods":"The STT multiprocessing is beautiful, although I still have the problem of having och cuts in the middle of sentences. I'll mitigate this by implementing a rolling window of recorded data, and create a python package for real time STT that I can use in the  uw_chess - [16:00]. Updated Readme and added some more visuals - [20:00]",
                    "insights":"The philosophy of mind is a topic I'm passionate about, and after building with multiprocessing  I get reminded of the integrated information theory of consciousness. Admittedly my understanding of the concept is superficial. But I think multiprocessing falls in line with that theory - [16:00].",
                    "conclusions":"Got to work harder, might have to many balls in the air, this logbook is only tracking one project by choice. This logbooks helps me have one project grounded and steady - [00:00].",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-14":{
                    "weekday": "Thursday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"There's a lot I want to get done today, the uw_realtime_stt package is the main focus. This will be a keystone for other projects I’m planning. What’s left for uw_realtime_stt 1.0.0-alpha is a rolling window analysis loop to mitigate cuts in the recording where audio is missed - [08:00]",
                    "agenda":["Rolling window analysis loop", "alpha build", "Demo video"],
                    "methods":"The rolling window isn’t going to work, it splits up audio in a uniform sequence, which leads to cuts in the middle of words. When the model predicts a sentence, it doesn't predict word by word, but makes a prediction on the entire audio, so if one word is cut off i will alter the rest of the sentence as well - [16:00]. Image above show's the last failed test of me reading a section from the logbook. “pyproject.toml” and directory structure is good to go as soon I'm ready with the buffer functionality for the audio stream - [01:30 Friday]",
                    "insights":"All of this is new and today it’s clear that I don't know enough to have an accurate feel for how long this is going to take. In essence I'm doing it correctly by creating a buffer, but my method of creating the buffer is a bit jerry-rigged. [01:30 Friday]",
                    "conclusions":"Ended the last coding session in a bad mood but had a really good blitz streak on chess.com for the past like 4h. Really tired now, but excited to finish this chess app. It’s going to feel great playing when it’s done - [01:30 Friday]",
                    "image": "./logbook/images/2023-12-14.png",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-15":{
                    "weekday": "Friday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Heading out to do some errands for the day but I'll squeeze in a session for the evening. It’s only one thing on the agenda, it's going to feel better adding tasks later, rather than not completing the task. Probably going to play some Blitz on chess.com to. It’s Friday after all - [10:30]",
                    "agenda":["Build and test audio buffer"],
                    "methods":"Barely got an hour coding on the real-time script, most just googling. Made one test with the buffer. I need to look at the appending buffer and stream to analyze workflow - [01:00 Saturday]",
                    "insights":"Nothing worth mentioning - [01:00 Saturday]",
                    "conclusions":"I know what to do now - [01:00 Saturday]",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-16":{
                    "weekday": "Saturday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Same thing as yesterday. The problem I'm having with realtime speech-to-text STT is that at some point the recording has to be cut and passed to the analyze function to predict the text. If a word is cut off it will alter the parts or the entire sentence to grammatically fit the sound of the word that is cut off in the end or beginning. To mitigate this the buffer should only be flushed when there is a clear pause in a sentence. Until it is flushed the whole buffer data will be analyzed on each iteration that sound is appended. This part is relatively straightforward using python multiprocessing, but it’s the audio streaming to the buffer I'm not sure how to implement correctly, it must be continuous without any sort of break. I've tried running two recording functions in tandem, but the library I'm using for audio recording isn’t meant to function like this. I might have to create my own for this. First I'll do some tests of asynchronous recording event loops and see if that is enough  - [14:00].",
                    "agenda":["Build and test audio buffer"],
                    "methods":"Buffer is working now as the sketch, just need to feed the prediction model. Moving away from Speech recognition and making a record function using Pydub library. Tomorrow I'll look at implementing predictions - [00:00].",
                    "insights":"Played chess until 4 in the morning. Had to blow off steam because of the lack of progress with the audio-buffer. At the end I was playing so badly that the attempt to blow off steam was counterproductive, it was still fun and I feel mentally and creatively replenished. - [14:00].", 
                    "conclusions":"Didn’t get as  much coding done today as i wanted, felt like tendering to other matters. But I need to step it up and finalize this so I can move on to the next project  - [00:00].",
                    "image": "./logbook/images/2023-12-16_sketch.png",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-17":{
                    "weekday": "Sunday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Today is the day to “Get everything to sing!“, not that confident I’ll finish it today, but as soon as the speech-to-text works I can then implement it into uw_chess. The speech to text package will also be a substantial feature on another project in the pipeline - [11:00]",
                    "agenda":["Buffer and analysis workflow", "Recode demo video"],
                    "methods":"The buffer works well but needs some optimizations for the condition that flushes the buffer when detecting silence. I ran into data conversion errors when analyzing and transcribing the audio. It works with the Whisper-STT model because it uses the same bytes data as the buffer stores the audio, but the free whisper API from Hugging Face interference is too slow for analyzing streams of audio. I would like to keep testing the workflow with google’s STT api, so I need to fix the conversion. It’s probably not a big issue to fix, I'm just not focused today. - [00:00].",
                    "insights":"Nothing worth mentioning - [00:00].", 
                    "conclusions":"Might be spreading myself too thin, I’ve gotten other important work done but I haven't given this STT my full attention this weekend. Haven’t rested property, need to get back to a better sleep cycle. It’s a new week tomorrow and it feels good!  - [00:00].",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-18":{
                    "weekday": "Monday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"New week, an opportunity to start fresh. I have projected down the pipeline that relies heavily on this speech to text component for uw_chess. I will make it work today - [07:00].",
                    "agenda":["Buffer and analysis workflow", "Recode demo video"],
                    "methods":"I’m so close, and really tired, I just need one or two more days before integrating this new STT to uw_chess. I’ve left google STT api behind one back to run Distil whisper-large locally. It works well but I keep getting a message that I need to add special tokens that it has not been trained on, which is really strange. I’ll look into what tokens are not included tomorrow- [Tuesday 02:00].",
                    "insights":"Started the morning listening to Elon Musk’s biography, it makes me want to work harder. I know what must be done, but lack consistency. Can’t rely on motivation, I need to update the system by which I operate - [07:00].", 
                    "conclusions":"Once I get this to work properly, I'm going to buy a box of wine and play chess until the box is empty - [Tuesday 02:00].",
                    "image": "./logbook/images/2023-12-16_sketch.png",
                    "video_url": "https://www.youtube.com/embed/QTmYrX1jGj0?si=6WBilxkGkbsHeVbr",
                    "alt_text": ""
                },
            "2023-12-19":{
                    "weekday": "Tuesday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"I’d like to finish what I believe to be the most critical components (listed below) that need to be addressed before I can move on to implementing uw_realtime_stt into uw_chess. The special tokens warning is driving me crazy, I need to figure out how to list the tokens that are not in the  tokenizer. Which seems to be like a needle in a haystack, there has to be a simple solution to this - [09:00].",
                    "agenda":["special tokens warning", "Install package test", "Improve responsiveness and speed"],
                    "methods":"The warning message might be a conflict with how the distill-whisper fork and the original whisper model are integrated with the transformers API, it’s a guess, but i don’t know. What I do know is that I need to create my own fine tuned version specifically for chess moves. Eny how, suppressed the message with a logging condition, not good practice but this isn’t the final product - [23:00]",
                    "insights":"Automatic speech recognition is like the phenomenon when lyrics in songs sound different depending on the listeners because the utterances of different sentences are phonetically sound very similar. Context is very important, and humans are very good at interpreting context. How do I design context? - [23.00]", 
                    "conclusions":"It’s late now - [01.30 wednesday]",
                    "image": "./logbook/images/2023-12-19.png",
                    "video_url": "",
                    "alt_text": ""
                },
            "2023-12-20":{
                    "weekday": "Wednesday",
                    "project":"uw-chess Blindfold Chess Trainer",
                    "objective":"Uw_realtime_stt is far from great, I might spin up a hugging face inference endpoint and test the speed improvement from stronger GPUs. 'perfection is the enemy of progress' and I need to move on. Once I've tried the uw_chess app with the modified STT I can rank what process needs to be received first - [08:30]",
                    "agenda":["Test Install package, commit-push", "Write Readme.md", "Test integrate with uw-chess"],
                    "methods":"|----|",
                    "insights":"I don’t think anyone is reading this logbook, but I feel a need to put more effort and care into it. If someone visits this logbook, it’s a snapshot of time and whatever they read will be the first impression that either captivates or repelle’s their attention. But also for my own sake, I can see myself reading this in the future and remembering what went down - [08:30]", 
                    "conclusions":"|----|",
                    "image": "",
                    "video_url": "",
                    "alt_text": ""
                }
        }
    }
}